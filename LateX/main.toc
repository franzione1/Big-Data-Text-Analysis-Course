\contentsline {section}{\numberline {1}Generalities and Map Reduce}{1}{section.1}%
\contentsline {subsection}{\numberline {1.1}Introduction to Distributed File Systems}{1}{subsection.1.1}%
\contentsline {subsection}{\numberline {1.2}Map Reduce}{2}{subsection.1.2}%
\contentsline {subsection}{\numberline {1.3}Distributed File System Architecture w/ Map Reduce}{3}{subsection.1.3}%
\contentsline {subsection}{\numberline {1.4}MapReduce in parallelo}{4}{subsection.1.4}%
\contentsline {subsection}{\numberline {1.5}Combiners}{4}{subsection.1.5}%
\contentsline {subsection}{\numberline {1.6}Remarks}{4}{subsection.1.6}%
\contentsline {subsection}{\numberline {1.7}Algoritmi che usano Map Reduce}{5}{subsection.1.7}%
\contentsline {subsubsection}{\numberline {1.7.1}Matrix-Vector multiplication - Vettore che sta in memoria}{5}{subsubsection.1.7.1}%
\contentsline {subsubsection}{\numberline {1.7.2}Matrix-Vector multiplication - Vettore che non sta in memoria}{6}{subsubsection.1.7.2}%
\contentsline {subsubsection}{\numberline {1.7.3}Relational algebra operations - Selection}{6}{subsubsection.1.7.3}%
\contentsline {subsubsection}{\numberline {1.7.4}Relational algebra operations - Projection}{6}{subsubsection.1.7.4}%
\contentsline {subsubsection}{\numberline {1.7.5}Relational algebra operations - Union}{6}{subsubsection.1.7.5}%
\contentsline {subsubsection}{\numberline {1.7.6}Relational algebra operations - Intersection}{6}{subsubsection.1.7.6}%
\contentsline {subsubsection}{\numberline {1.7.7}Relational algebra operations - Difference}{7}{subsubsection.1.7.7}%
\contentsline {subsubsection}{\numberline {1.7.8}Relational algebra operations - Natural Join}{7}{subsubsection.1.7.8}%
\contentsline {subsubsection}{\numberline {1.7.9}Relational algebra operations - Grouping and Aggregation}{7}{subsubsection.1.7.9}%
\contentsline {subsubsection}{\numberline {1.7.10}Matrix multiplication}{7}{subsubsection.1.7.10}%
\contentsline {subsection}{\numberline {1.8}Remarks}{8}{subsection.1.8}%
\contentsline {subsubsection}{\numberline {1.8.1}Reducer size \textit {q}}{8}{subsubsection.1.8.1}%
\contentsline {subsubsection}{\numberline {1.8.2}Replication rate \textit {r}}{8}{subsubsection.1.8.2}%
\contentsline {subsubsection}{\numberline {1.8.3}Similarity Join}{8}{subsubsection.1.8.3}%
\contentsline {section}{\numberline {2}Data Mining}{9}{section.2}%
\contentsline {subsection}{\numberline {2.1}Principio di Bonferroni}{9}{subsection.2.1}%
\contentsline {subsubsection}{\numberline {2.1.1}Esempio dei malfattori}{9}{subsubsection.2.1.1}%
\contentsline {section}{\numberline {3}Machine Learning}{10}{section.3}%
\contentsline {subsection}{\numberline {3.1}Perchè utilizzare il Machine Learning?}{10}{subsection.3.1}%
\contentsline {subsection}{\numberline {3.2}Tipologie di apprendimento}{10}{subsection.3.2}%
\contentsline {subsection}{\numberline {3.3}Risultato}{11}{subsection.3.3}%
\contentsline {subsection}{\numberline {3.4}Tipologie di modelli}{11}{subsection.3.4}%
\contentsline {subsection}{\numberline {3.5}Regressione}{12}{subsection.3.5}%
\contentsline {subsubsection}{\numberline {3.5.1}Regressione lineare}{12}{subsubsection.3.5.1}%
\contentsline {subsubsection}{\numberline {3.5.2}Decision Tree}{13}{subsubsection.3.5.2}%
\contentsline {subsubsection}{\numberline {3.5.3}Costruzione di un Decision Tree}{14}{subsubsection.3.5.3}%
\contentsline {subsubsection}{\numberline {3.5.4}Simple Algorithm}{15}{subsubsection.3.5.4}%
\contentsline {subsection}{\numberline {3.6}Overfitting}{15}{subsection.3.6}%
\contentsline {subsubsection}{\numberline {3.6.1}i.i.d. assumption per Statistical Modeling}{15}{subsubsection.3.6.1}%
\contentsline {subsection}{\numberline {3.7}Instance based learning}{16}{subsection.3.7}%
\contentsline {subsection}{\numberline {3.8}One rule algorithm}{16}{subsection.3.8}%
\contentsline {subsection}{\numberline {3.9}Naive Bayes Classifier}{17}{subsection.3.9}%
\contentsline {subsubsection}{\numberline {3.9.1}Regola di Bayes}{18}{subsubsection.3.9.1}%
\contentsline {subsection}{\numberline {3.10}Unsupervised Learning}{19}{subsection.3.10}%
\contentsline {subsubsection}{\numberline {3.10.1}Clustering}{19}{subsubsection.3.10.1}%
\contentsline {subsection}{\numberline {3.11}Come trovo un modello che non overfitta?}{20}{subsection.3.11}%
\contentsline {subsection}{\numberline {3.12}Come posso aiutare il modello contro l'overfitting?}{20}{subsection.3.12}%
\contentsline {subsection}{\numberline {3.13}Valutazione del modello}{20}{subsection.3.13}%
\contentsline {subsubsection}{\numberline {3.13.1}F1 score}{21}{subsubsection.3.13.1}%
\contentsline {subsubsection}{\numberline {3.13.2}Multilabel Confusion Matrix}{21}{subsubsection.3.13.2}%
\contentsline {subsection}{\numberline {3.14}Ensemble learning}{21}{subsection.3.14}%
\contentsline {subsubsection}{\numberline {3.14.1}Bagging}{21}{subsubsection.3.14.1}%
\contentsline {subsubsection}{\numberline {3.14.2}Boosting}{21}{subsubsection.3.14.2}%
\contentsline {section}{\numberline {4}Discovering frequent itemsets}{23}{section.4}%
\contentsline {subsection}{\numberline {4.1}Market-Basket model}{23}{subsection.4.1}%
\contentsline {subsubsection}{\numberline {4.1.1}Principio di monotonicità}{23}{subsubsection.4.1.1}%
\contentsline {subsubsection}{\numberline {4.1.2}Confidence}{24}{subsubsection.4.1.2}%
\contentsline {subsection}{\numberline {4.2}Representation of the Market-Basket data}{24}{subsection.4.2}%
\contentsline {subsubsection}{\numberline {4.2.1}Triangular Matrix e Triplets}{24}{subsubsection.4.2.1}%
\contentsline {subsubsection}{\numberline {4.2.2}A-Priori Algorithm}{25}{subsubsection.4.2.2}%
\contentsline {subsubsection}{\numberline {4.2.3}Park, Chen, Yu Algorithm}{25}{subsubsection.4.2.3}%
\contentsline {subsubsection}{\numberline {4.2.4}Limited Pass Algorithm}{26}{subsubsection.4.2.4}%
\contentsline {subsubsection}{\numberline {4.2.5}Toivonen's Algorithm}{26}{subsubsection.4.2.5}%
\contentsline {subsubsection}{\numberline {4.2.6}SON Algorithm (Savasere, Omiecinski and Navathe)}{27}{subsubsection.4.2.6}%
\contentsline {subsection}{\numberline {4.3}Finding Similar Items}{28}{subsection.4.3}%
\contentsline {subsubsection}{\numberline {4.3.1}Shingling}{28}{subsubsection.4.3.1}%
\contentsline {subsubsection}{\numberline {4.3.2}Minhashing}{29}{subsubsection.4.3.2}%
\contentsline {subsubsection}{\numberline {4.3.3}Minhashing optimization}{31}{subsubsection.4.3.3}%
\contentsline {subsubsection}{\numberline {4.3.4}Locality-sensitive hashing}{31}{subsubsection.4.3.4}%
\contentsline {section}{\numberline {5}Text Analysis}{35}{section.5}%
\contentsline {subsection}{\numberline {5.1}Text Data Access}{35}{subsection.5.1}%
\contentsline {subsection}{\numberline {5.2}Text Retrieval}{35}{subsection.5.2}%
\contentsline {subsubsection}{\numberline {5.2.1}Document Selection vs Document Ranking}{35}{subsubsection.5.2.1}%
\contentsline {subsection}{\numberline {5.3}Retrieval Models}{36}{subsection.5.3}%
\contentsline {subsubsection}{\numberline {5.3.1}Vector Space Retrieval Model}{36}{subsubsection.5.3.1}%
\contentsline {subsection}{\numberline {5.4}Probabilistic Retrieval Models}{38}{subsection.5.4}%
\contentsline {subsubsection}{\numberline {5.4.1}Text statistics: Zipf's Law}{38}{subsubsection.5.4.1}%
\contentsline {subsubsection}{\numberline {5.4.2}Language Model}{38}{subsubsection.5.4.2}%
\contentsline {subsection}{\numberline {5.5}Probabilistic Retrieval Models II}{41}{subsection.5.5}%
\contentsline {subsubsection}{\numberline {5.5.1}The Query Likelihood Retrieval Model}{41}{subsubsection.5.5.1}%
\contentsline {subsubsection}{\numberline {5.5.2}Smoothing della probabilità}{42}{subsubsection.5.5.2}%
\contentsline {subsection}{\numberline {5.6}Search Engine Implementation}{43}{subsection.5.6}%
\contentsline {subsubsection}{\numberline {5.6.1}Tokenizer e Indexer}{43}{subsubsection.5.6.1}%
\contentsline {subsubsection}{\numberline {5.6.2}Scorer e Learner}{44}{subsubsection.5.6.2}%
\contentsline {subsubsection}{\numberline {5.6.3}Rocchio Feedback}{44}{subsubsection.5.6.3}%
\contentsline {subsection}{\numberline {5.7}Text classification}{45}{subsection.5.7}%
\contentsline {subsubsection}{\numberline {5.7.1}Computational Lexical Semantics}{45}{subsubsection.5.7.1}%
\contentsline {subsubsection}{\numberline {5.7.2}Vector semantics and embeddings}{46}{subsubsection.5.7.2}%
\contentsline {subsubsection}{\numberline {5.7.3}Sparse vector representations: Term-document matrix}{47}{subsubsection.5.7.3}%
\contentsline {subsubsection}{\numberline {5.7.4}Sparse vector representations: word-word or term-context matrix}{47}{subsubsection.5.7.4}%
\contentsline {subsubsection}{\numberline {5.7.5}Positive Pointwise Mutual Information}{47}{subsubsection.5.7.5}%
\contentsline {subsubsection}{\numberline {5.7.6}Singular Value Decomposition (SVD) e Latent Semantic Analysis (LSA)}{48}{subsubsection.5.7.6}%
\contentsline {subsubsection}{\numberline {5.7.7}Word2vec}{48}{subsubsection.5.7.7}%
\contentsline {subsection}{\numberline {5.8}Neural Networks Basics}{49}{subsection.5.8}%
\contentsline {subsubsection}{\numberline {5.8.1}Feed Forward Neural Networks}{49}{subsubsection.5.8.1}%
\contentsline {subsection}{\numberline {5.9}Recurrent Neural Networks}{50}{subsection.5.9}%
\contentsline {subsubsection}{\numberline {5.9.1}Sequence classification}{50}{subsubsection.5.9.1}%
\contentsline {subsection}{\numberline {5.10}Contextualized embeddings}{50}{subsection.5.10}%
\contentsline {subsubsection}{\numberline {5.10.1}Transformers}{50}{subsubsection.5.10.1}%
\contentsline {subsubsection}{\numberline {5.10.2}Multihead attention mechanism}{51}{subsubsection.5.10.2}%
\contentsline {section}{\numberline {6}Explainable AI}{53}{section.6}%
\contentsline {subsection}{\numberline {6.1}Interpretability}{53}{subsection.6.1}%
\contentsline {subsubsection}{\numberline {6.1.1}Interpretable Models}{53}{subsubsection.6.1.1}%
\contentsline {subsubsection}{\numberline {6.1.2}Partial Dependence Plot}{54}{subsubsection.6.1.2}%
\contentsline {subsubsection}{\numberline {6.1.3}Permutation Feature Importance}{54}{subsubsection.6.1.3}%
\contentsline {subsubsection}{\numberline {6.1.4}Leave-One-Covariate-Out}{54}{subsubsection.6.1.4}%
\contentsline {subsubsection}{\numberline {6.1.5}Local Surrogate (LIME)}{55}{subsubsection.6.1.5}%
\contentsline {subsubsection}{\numberline {6.1.6}Counterfactual Explanation}{55}{subsubsection.6.1.6}%
\contentsline {subsubsection}{\numberline {6.1.7}Shapley Values}{55}{subsubsection.6.1.7}%
\contentsline {subsubsection}{\numberline {6.1.8}KernelSHAP}{56}{subsubsection.6.1.8}%
\contentsline {section}{\numberline {7}MLOps}{57}{section.7}%
\contentsline {subsection}{\numberline {7.1}Project Life-Cycle}{57}{subsection.7.1}%
\contentsline {subsection}{\numberline {7.2}Perchè i progetti di ML falliscono?}{57}{subsection.7.2}%
\contentsline {subsubsection}{\numberline {7.2.1}Mettere un modello in produzione: mlops}{58}{subsubsection.7.2.1}%
\contentsline {subsubsection}{\numberline {7.2.2}Problemi con i dati}{58}{subsubsection.7.2.2}%
\contentsline {subsubsection}{\numberline {7.2.3}Training and evaluation}{58}{subsubsection.7.2.3}%
\contentsline {subsection}{\numberline {7.3}Fairness in ML}{59}{subsection.7.3}%
\contentsline {subsubsection}{\numberline {7.3.1}No fairness through unawareness}{59}{subsubsection.7.3.1}%
\contentsline {subsubsection}{\numberline {7.3.2}Pitfalls of action}{59}{subsubsection.7.3.2}%
\contentsline {subsubsection}{\numberline {7.3.3}Statistical non-discrimination criteria}{59}{subsubsection.7.3.3}%
\contentsline {subsubsection}{\numberline {7.3.4}Separation}{60}{subsubsection.7.3.4}%
\contentsline {subsubsection}{\numberline {7.3.5}Sufficiency}{60}{subsubsection.7.3.5}%
\contentsline {subsection}{\numberline {7.4}Come rimuoviamo gli stereotipi?}{60}{subsection.7.4}%
